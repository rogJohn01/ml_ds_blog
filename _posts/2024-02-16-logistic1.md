---
layout: post
title: "Derive gradient descent of logistic regression"
categories: ML

---

Loss function :
<br>

$$
\ell(y, \hat{y}) = -\left[ y \log(\hat{y}) + (1 - y) \log(1 - \hat{y}) \right]
$$

cost function : 
<br>

$$
J(w) = - \frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \log(\hat{y}^{(i)}) + (1 - y^{(i)}) \log(1 - \hat{y}^{(i)}) \right]
$$

$$

\frac{\partial J(w)}{\partial w_j} = \frac{\partial J(w)}{\partial \hat{y}^{(i)}} \cdot \frac{\partial \hat{y}^{(i)}}{\partial z^{(i)}} \cdot \frac{\partial z^{(i)}}{\partial w_j}
$$

differntiation of natural log 
<br>

$$
\frac{\partial J(w)}{\partial w_j} = - \frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \frac{1}{\hat{y}^{(i)}} - (1 - y^{(i)}) \frac{1}{1 - \hat{y}^{(i)}} \right] \frac{\partial \hat{y}^{(i)}}{\partial w_j}
$$


$$
\frac{\partial \hat{y}^{(i)}}{\partial w_j} = \frac{\partial \hat{y}^{(i)}}{\partial z^{(i)}} \cdot \frac{\partial z^{(i)}}{\partial w_j}

$$

$$
\frac{\partial \hat{y}^{(i)}}{\partial w_j} = \hat{y}^{(i)} (1 - \hat{y}^{(i)}) \frac{\partial z^{(i)}}{\partial w_j}

$$

$$
z^{(i)} = w_1 x_1^{(i)} + w_2 x_2^{(i)} + \cdots + w_n x_n^{(i)} + b

$$

$$
\frac{\partial z^{(i)}}{\partial w_j} = x_j^{(i)}

$$

$$
\frac{\partial J(w)}{\partial w_j} = - \frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \frac{1}{\hat{y}^{(i)}} - (1 - y^{(i)}) \frac{1}{1 - \hat{y}^{(i)}} \right] \hat{y}^{(i)} (1 - \hat{y}^{(i)}) x_j^{(i)}
$$


$$
= y^{(i)} (1 - \hat{y}^{(i)}) - (1 - y^{(i)}) \hat{y}^{(i)}

$$

$$

=y^{(i)} - y^{(i)} \hat{y}^{(i)} - \hat{y}^{(i)} + y^{(i)} \hat{y}^{(i)}

$$


$$
=y^{(i)} - \hat{y}^{(i)}


$$

$$
\frac{\partial J(w)}{\partial w_j} = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)}) x_j^{(i)}

$$

$$
w_j := w_j - \alpha \frac{\partial}{\partial w_j} J(\mathbf{w}, b) 
$$